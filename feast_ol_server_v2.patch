diff --git a/sdk/python/feast/data_source.py b/sdk/python/feast/data_source.py
index a8410fbf..b6e6cd56 100644
--- a/sdk/python/feast/data_source.py
+++ b/sdk/python/feast/data_source.py
@@ -329,7 +329,7 @@ class DataSource(ABC):
 
     @staticmethod
     @abstractmethod
-    def from_proto(data_source: DataSourceProto) -> Any:
+    def from_proto(data_source: DataSourceProto, **kwargs) -> Any:
         """
         Converts data source config in FeatureTable spec to a DataSource class object.
 
@@ -344,7 +344,7 @@ class DataSource(ABC):
         """
         if data_source.data_source_class_type:
             cls = get_data_source_class_from_type(data_source.data_source_class_type)
-            return cls.from_proto(data_source)
+            return cls.from_proto(data_source, **kwargs)
 
         if data_source.file_options.file_format and data_source.file_options.file_url:
             from feast.infra.offline_stores.file_source import FileSource
diff --git a/sdk/python/feast/feature_store.py b/sdk/python/feast/feature_store.py
index 9655c5d1..8d2bf02f 100644
--- a/sdk/python/feast/feature_store.py
+++ b/sdk/python/feast/feature_store.py
@@ -122,6 +122,10 @@ class FeatureStore:
         """Gets the project of this feature store."""
         return self.config.project
 
+    @project.setter
+    def project(self, project:str) -> None:
+        self.config.project = project
+
     def _get_provider(self) -> Provider:
         # TODO: Bake self.repo_path into self.config so that we dont only have one interface to paths
         return self._provider
@@ -511,6 +515,38 @@ class FeatureStore:
                 table, project=self.project, commit=False
             )
 
+        add_odfvs = [o.name for o in odfvs_to_update]
+        add_feature_tables = [ft.name for ft in tables_to_update]
+
+        add_entities = [{
+            'name': ent.name,
+            'data_type': ent.value_type.name
+            }
+            for ent in entities_to_update]
+
+        add_feature_views = [{
+            'name': fv.name,
+            'entities': fv.entities
+        }
+        for fv in views_to_update]
+
+        add_feature_services = [{
+            'name': fs.name,
+            'features': fs.features
+        }
+        for fs in services_to_update]
+
+        infra_update = {
+            "project": self.project,
+            "to_add": {
+                "entities": add_entities,
+                "feature_views": add_feature_views,
+                "odfvs": add_odfvs,
+                "feature_services": add_feature_services,
+                "feature_tables": add_feature_tables
+            }
+        }
+
         if not partial:
             # Delete all registry objects that should not exist.
             entities_to_delete = [
@@ -557,6 +593,39 @@ class FeatureStore:
                     table.name, project=self.project, commit=False
                 )
 
+        delete_odfvs = [o.name for o in odfvs_to_delete]
+        delete_feature_tables = [ft.name for ft in tables_to_delete]
+
+        delete_entities = [{
+            'name': ent.name,
+            'data_type': ent.value_type.name
+            }
+            for ent in entities_to_delete]
+
+        delete_feature_views = [{
+            'name': fv.name,
+            'entities': fv.entities
+        }
+        for fv in views_to_delete]
+
+        delete_feature_services = [{
+            'name': fs.name,
+            'features': fs.features
+        }
+        for fs in services_to_delete]
+
+        infra_update["to_delete"] = {
+            "entities": delete_entities,
+            "feature_views": delete_feature_views,
+            "odfvs": delete_odfvs,
+            "feature_services": delete_feature_services,
+            "feature_tables": delete_feature_tables
+        }
+
+        if "dkuberegistrystore" == self._registry._registry_store.__class__.__name__.lower():
+            self._registry.update_newly_added_attrs(infra_update)
+            self._registry.validate_infra_update(infra_update)
+
         self._get_provider().update_infra(
             project=self.project,
             tables_to_delete=views_to_delete + tables_to_delete if not partial else [],
@@ -566,7 +635,11 @@ class FeatureStore:
             partial=partial,
         )
 
-        self._registry.commit()
+        if "dkuberegistrystore" == self._registry._registry_store.__class__.__name__.lower():
+            self._registry.commit(
+                project=self.project, to_add=infra_update['to_add'], to_delete=infra_update['to_delete'])
+        else:
+            self._registry.commit()
 
     @log_exceptions_and_usage
     def teardown(self):
@@ -581,7 +654,7 @@ class FeatureStore:
         entities = self.list_entities()
 
         self._get_provider().teardown_infra(self.project, tables, entities)
-        self._registry.teardown()
+        self._registry.teardown(project=self.project)
 
     @log_exceptions_and_usage
     def get_historical_features(
@@ -724,6 +797,7 @@ class FeatureStore:
     @log_exceptions_and_usage
     def materialize_incremental(
         self, end_date: datetime, feature_views: Optional[List[str]] = None,
+        user: Optional[str] = None, offline_dataset: Optional[str] = None
     ) -> None:
         """
         Materialize incremental new data from the offline store into the online store.
@@ -792,15 +866,28 @@ class FeatureStore:
             start_date = utils.make_tzaware(start_date)
             end_date = utils.make_tzaware(end_date)
 
-            provider.materialize_single_feature_view(
-                config=self.config,
-                feature_view=feature_view,
-                start_date=start_date,
-                end_date=end_date,
-                registry=self._registry,
-                project=self.project,
-                tqdm_builder=tqdm_builder,
-            )
+            if "dkuberegistrystore" == self._registry._registry_store.__class__.__name__.lower():
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                    user=user,
+                    offline_dataset=offline_dataset
+                )
+            else:
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                )
 
             self._registry.apply_materialization(
                 feature_view, self.project, start_date, end_date
@@ -812,6 +899,8 @@ class FeatureStore:
         start_date: datetime,
         end_date: datetime,
         feature_views: Optional[List[str]] = None,
+        user: Optional[str] = None,
+        offline_dataset: Optional[str] = None
     ) -> None:
         """
         Materialize data from the offline store into the online store.
@@ -872,15 +961,28 @@ class FeatureStore:
             start_date = utils.make_tzaware(start_date)
             end_date = utils.make_tzaware(end_date)
 
-            provider.materialize_single_feature_view(
-                config=self.config,
-                feature_view=feature_view,
-                start_date=start_date,
-                end_date=end_date,
-                registry=self._registry,
-                project=self.project,
-                tqdm_builder=tqdm_builder,
-            )
+            if "dkuberegistrystore" == self._registry._registry_store.__class__.__name__.lower():
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                    user=user,
+                    offline_dataset=offline_dataset
+                )
+            else:
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                )
 
             self._registry.apply_materialization(
                 feature_view, self.project, start_date, end_date
diff --git a/sdk/python/feast/feature_view.py b/sdk/python/feast/feature_view.py
index ac8abefe..3538bca3 100644
--- a/sdk/python/feast/feature_view.py
+++ b/sdk/python/feast/feature_view.py
@@ -330,7 +330,7 @@ class FeatureView(BaseFeatureView):
         return FeatureViewProto(spec=spec, meta=meta)
 
     @classmethod
-    def from_proto(cls, feature_view_proto: FeatureViewProto):
+    def from_proto(cls, feature_view_proto: FeatureViewProto, **kwargs):
         """
         Creates a feature view from a protobuf representation of a feature view.
 
@@ -340,7 +340,7 @@ class FeatureView(BaseFeatureView):
         Returns:
             A FeatureViewProto object based on the feature view protobuf.
         """
-        batch_source = DataSource.from_proto(feature_view_proto.spec.batch_source)
+        batch_source = DataSource.from_proto(feature_view_proto.spec.batch_source, **kwargs)
         stream_source = (
             DataSource.from_proto(feature_view_proto.spec.stream_source)
             if feature_view_proto.spec.HasField("stream_source")
diff --git a/sdk/python/feast/infra/passthrough_provider.py b/sdk/python/feast/infra/passthrough_provider.py
index 34bf4902..4254a87c 100644
--- a/sdk/python/feast/infra/passthrough_provider.py
+++ b/sdk/python/feast/infra/passthrough_provider.py
@@ -74,9 +74,16 @@ class PassthroughProvider(Provider):
             Tuple[EntityKeyProto, Dict[str, ValueProto], datetime, Optional[datetime]]
         ],
         progress: Optional[Callable[[int], Any]],
+        user: Optional[str] = None
     ) -> None:
         set_usage_attribute("provider", self.__class__.__name__)
-        self.online_store.online_write_batch(config, table, data, progress)
+        registry_store = self.get_registry_type()
+        if registry_store and "dkuberegistrystore" in registry_store.lower():
+            self.online_store.online_write_batch(
+                config, table, data, progress, user
+            )
+        else:
+            self.online_store.online_write_batch(config, table, data, progress)
 
     @log_exceptions_and_usage(sampler=RatioSampler(ratio=0.001))
     def online_read(
@@ -116,6 +123,8 @@ class PassthroughProvider(Provider):
         registry: Registry,
         project: str,
         tqdm_builder: Callable[[int], tqdm],
+        user: Optional[str] = None,
+        offline_dataset: Optional[str] = None
     ) -> None:
         set_usage_attribute("provider", self.__class__.__name__)
 
@@ -130,16 +139,31 @@ class PassthroughProvider(Provider):
             created_timestamp_column,
         ) = _get_column_names(feature_view, entities)
 
-        offline_job = self.offline_store.pull_latest_from_table_or_query(
-            config=config,
-            data_source=feature_view.batch_source,
-            join_key_columns=join_key_columns,
-            feature_name_columns=feature_name_columns,
-            event_timestamp_column=event_timestamp_column,
-            created_timestamp_column=created_timestamp_column,
-            start_date=start_date,
-            end_date=end_date,
-        )
+        registry_store = self.get_registry_type()
+        if registry_store and "dkuberegistrystore" in registry_store.lower():
+            offline_job = self.offline_store.pull_latest_from_table_or_query(
+                config=config,
+                data_source=feature_view.batch_source,
+                join_key_columns=join_key_columns,
+                feature_name_columns=feature_name_columns,
+                event_timestamp_column=event_timestamp_column,
+                created_timestamp_column=created_timestamp_column,
+                start_date=start_date,
+                end_date=end_date,
+                user=user,
+                offline_dataset=offline_dataset
+            )
+        else:
+            offline_job = self.offline_store.pull_latest_from_table_or_query(
+                config=config,
+                data_source=feature_view.batch_source,
+                join_key_columns=join_key_columns,
+                feature_name_columns=feature_name_columns,
+                event_timestamp_column=event_timestamp_column,
+                created_timestamp_column=created_timestamp_column,
+                start_date=start_date,
+                end_date=end_date,
+            )
 
         table = offline_job.to_arrow()
 
@@ -148,15 +172,27 @@ class PassthroughProvider(Provider):
 
         join_keys = [entity.join_key for entity in entities]
 
-        with tqdm_builder(table.num_rows) as pbar:
-            for batch in table.to_batches(DEFAULT_BATCH_SIZE):
-                rows_to_write = _convert_arrow_to_proto(batch, feature_view, join_keys)
-                self.online_write_batch(
-                    self.repo_config,
-                    feature_view,
-                    rows_to_write,
-                    lambda x: pbar.update(x),
-                )
+        if registry_store and "dkuberegistrystore" in registry_store.lower():
+            with tqdm_builder(table.num_rows) as pbar:
+                for batch in table.to_batches(DEFAULT_BATCH_SIZE):
+                    rows_to_write = _convert_arrow_to_proto(batch, feature_view, join_keys)
+                    self.online_write_batch(
+                        self.repo_config,
+                        feature_view,
+                        rows_to_write,
+                        lambda x: pbar.update(x),
+                        user
+                    )
+        else:
+            with tqdm_builder(table.num_rows) as pbar:
+                for batch in table.to_batches(DEFAULT_BATCH_SIZE):
+                    rows_to_write = _convert_arrow_to_proto(batch, feature_view, join_keys)
+                    self.online_write_batch(
+                        self.repo_config,
+                        feature_view,
+                        rows_to_write,
+                        lambda x: pbar.update(x),
+                    )
 
     def get_historical_features(
         self,
@@ -180,3 +216,8 @@ class PassthroughProvider(Provider):
             full_feature_names=full_feature_names,
         )
         return job
+
+    def get_registry_type(self):
+        registry_cfg = self.repo_config.get_registry_config()
+        registry_type = registry_cfg.registry_store_type.lower()
+        return registry_type
diff --git a/sdk/python/feast/registry.py b/sdk/python/feast/registry.py
index 8cb646f6..e3077303 100644
--- a/sdk/python/feast/registry.py
+++ b/sdk/python/feast/registry.py
@@ -14,7 +14,7 @@
 
 from datetime import datetime, timedelta
 from pathlib import Path
-from typing import Dict, List, Optional
+from typing import Dict, List, Optional, Set, Tuple, Union
 from urllib.parse import urlparse
 
 from google.protobuf.internal.containers import RepeatedCompositeFieldContainer
@@ -116,10 +116,13 @@ class Registry:
             else 0
         )
 
-    def _initialize_registry(self):
+    def _initialize_registry(self, project=None):
         """Explicitly initializes the registry with an empty proto if it doesn't exist."""
         try:
-            self._get_registry_proto()
+            if project:
+                self._get_registry_proto(project=project)
+            else:
+                self._get_registry_proto()
         except FileNotFoundError:
             registry_proto = RegistryProto()
             registry_proto.registry_schema_version = REGISTRY_SCHEMA_VERSION
@@ -165,7 +168,7 @@ class Registry:
         Returns:
             List of entities
         """
-        registry_proto = self._get_registry_proto(allow_cache=allow_cache)
+        registry_proto = self._get_registry_proto(allow_cache=allow_cache, project=project)
         entities = []
         for entity_proto in registry_proto.entities:
             if entity_proto.spec.project == project:
@@ -185,7 +188,7 @@ class Registry:
         feature_service_proto = feature_service.to_proto()
         feature_service_proto.spec.project = project
 
-        registry = self._prepare_registry_for_changes()
+        registry = self._prepare_registry_for_changes(project=project)
 
         for idx, existing_feature_service_proto in enumerate(registry.feature_services):
             if (
@@ -212,7 +215,7 @@ class Registry:
             List of feature services
         """
 
-        registry = self._get_registry_proto(allow_cache=allow_cache)
+        registry = self._get_registry_proto(allow_cache=allow_cache, project=project)
         feature_services = []
         for feature_service_proto in registry.feature_services:
             if feature_service_proto.spec.project == project:
@@ -235,7 +238,7 @@ class Registry:
             Returns either the specified feature service, or raises an exception if
             none is found
         """
-        registry = self._get_registry_proto(allow_cache=allow_cache)
+        registry = self._get_registry_proto(allow_cache=allow_cache, project=project)
 
         for feature_service_proto in registry.feature_services:
             if (
@@ -257,7 +260,7 @@ class Registry:
             Returns either the specified entity, or raises an exception if
             none is found
         """
-        registry_proto = self._get_registry_proto(allow_cache=allow_cache)
+        registry_proto = self._get_registry_proto(allow_cache=allow_cache, project=project)
         for entity_proto in registry_proto.entities:
             if entity_proto.spec.name == name and entity_proto.spec.project == project:
                 return Entity.from_proto(entity_proto)
@@ -277,7 +280,7 @@ class Registry:
         feature_table.is_valid()
         feature_table_proto = feature_table.to_proto()
         feature_table_proto.spec.project = project
-        self._prepare_registry_for_changes()
+        self._prepare_registry_for_changes(project=project)
         assert self.cached_registry_proto
 
         for idx, existing_feature_table_proto in enumerate(
@@ -308,7 +311,7 @@ class Registry:
         feature_view.ensure_valid()
         feature_view_proto = feature_view.to_proto()
         feature_view_proto.spec.project = project
-        self._prepare_registry_for_changes()
+        self._prepare_registry_for_changes(project=project)
         assert self.cached_registry_proto
 
         self._check_conflicting_feature_view_names(feature_view)
@@ -362,7 +365,7 @@ class Registry:
             List of on demand feature views
         """
 
-        registry = self._get_registry_proto(allow_cache=allow_cache)
+        registry = self._get_registry_proto(allow_cache=allow_cache, project=project)
         on_demand_feature_views = []
         for on_demand_feature_view in registry.on_demand_feature_views:
             if on_demand_feature_view.spec.project == project:
@@ -385,7 +388,7 @@ class Registry:
             Returns either the specified on demand feature view, or raises an exception if
             none is found
         """
-        registry = self._get_registry_proto(allow_cache=allow_cache)
+        registry = self._get_registry_proto(allow_cache=allow_cache, project=project)
 
         for on_demand_feature_view in registry.on_demand_feature_views:
             if (
@@ -413,7 +416,7 @@ class Registry:
             end_date (datetime): End date of the materialization interval to track
             commit: Whether the change should be persisted immediately
         """
-        self._prepare_registry_for_changes()
+        self._prepare_registry_for_changes(project=project)
         assert self.cached_registry_proto
 
         for idx, existing_feature_view_proto in enumerate(
@@ -424,7 +427,7 @@ class Registry:
                 and existing_feature_view_proto.spec.project == project
             ):
                 existing_feature_view = FeatureView.from_proto(
-                    existing_feature_view_proto
+                    existing_feature_view_proto, project=project
                 )
                 existing_feature_view.materialization_intervals.append(
                     (start_date, end_date)
@@ -434,7 +437,8 @@ class Registry:
                 del self.cached_registry_proto.feature_views[idx]
                 self.cached_registry_proto.feature_views.append(feature_view_proto)
                 if commit:
-                    self.commit()
+                    kwds = {"project": project}
+                    self.commit(**kwds)
                 return
 
         raise FeatureViewNotFoundException(feature_view.name, project)
@@ -449,7 +453,7 @@ class Registry:
         Returns:
             List of feature tables
         """
-        registry_proto = self._get_registry_proto()
+        registry_proto = self._get_registry_proto(project=project)
         feature_tables = []
         for feature_table_proto in registry_proto.feature_tables:
             if feature_table_proto.spec.project == project:
@@ -469,11 +473,11 @@ class Registry:
         Returns:
             List of feature views
         """
-        registry_proto = self._get_registry_proto(allow_cache=allow_cache)
+        registry_proto = self._get_registry_proto(allow_cache=allow_cache, project=project)
         feature_views: List[FeatureView] = []
         for feature_view_proto in registry_proto.feature_views:
             if feature_view_proto.spec.project == project:
-                feature_views.append(FeatureView.from_proto(feature_view_proto))
+                feature_views.append(FeatureView.from_proto(feature_view_proto, project=project))
         return feature_views
 
     def list_request_feature_views(
@@ -489,7 +493,7 @@ class Registry:
         Returns:
             List of feature views
         """
-        registry_proto = self._get_registry_proto(allow_cache=allow_cache)
+        registry_proto = self._get_registry_proto(allow_cache=allow_cache, project=project)
         feature_views: List[RequestFeatureView] = []
         for request_feature_view_proto in registry_proto.request_feature_views:
             if request_feature_view_proto.spec.project == project:
@@ -510,7 +514,7 @@ class Registry:
             Returns either the specified feature table, or raises an exception if
             none is found
         """
-        registry_proto = self._get_registry_proto()
+        registry_proto = self._get_registry_proto(project=project)
         for feature_table_proto in registry_proto.feature_tables:
             if (
                 feature_table_proto.spec.name == name
@@ -534,13 +538,13 @@ class Registry:
             Returns either the specified feature view, or raises an exception if
             none is found
         """
-        registry_proto = self._get_registry_proto(allow_cache=allow_cache)
+        registry_proto = self._get_registry_proto(allow_cache=allow_cache, project=project)
         for feature_view_proto in registry_proto.feature_views:
             if (
                 feature_view_proto.spec.name == name
                 and feature_view_proto.spec.project == project
             ):
-                return FeatureView.from_proto(feature_view_proto)
+                return FeatureView.from_proto(feature_view_proto, project=project)
         raise FeatureViewNotFoundException(name, project)
 
     def delete_feature_service(self, name: str, project: str, commit: bool = True):
@@ -552,7 +556,7 @@ class Registry:
             project: Feast project that this feature service belongs to
             commit: Whether the change should be persisted immediately
         """
-        self._prepare_registry_for_changes()
+        self._prepare_registry_for_changes(project=project)
         assert self.cached_registry_proto
 
         for idx, feature_service_proto in enumerate(
@@ -577,7 +581,7 @@ class Registry:
             project: Feast project that this feature table belongs to
             commit: Whether the change should be persisted immediately
         """
-        self._prepare_registry_for_changes()
+        self._prepare_registry_for_changes(project=project)
         assert self.cached_registry_proto
 
         for idx, existing_feature_table_proto in enumerate(
@@ -603,7 +607,7 @@ class Registry:
             project: Feast project that this feature view belongs to
             commit: Whether the change should be persisted immediately
         """
-        self._prepare_registry_for_changes()
+        self._prepare_registry_for_changes(project=project)
         assert self.cached_registry_proto
 
         for idx, existing_feature_view_proto in enumerate(
@@ -641,7 +645,7 @@ class Registry:
             project: Feast project that this entity belongs to
             commit: Whether the change should be persisted immediately
         """
-        self._prepare_registry_for_changes()
+        self._prepare_registry_for_changes(project=project)
         assert self.cached_registry_proto
 
         for idx, existing_entity_proto in enumerate(
@@ -658,23 +662,36 @@ class Registry:
 
         raise EntityNotFoundException(name, project)
 
-    def commit(self):
+    def commit(self, **kwargs):
         """Commits the state of the registry cache to the remote registry store."""
-        if self.cached_registry_proto:
+        if "dkuberegistrystore" == self._registry_store.__class__.__name__.lower():
+            kwargs.setdefault("to_add", {})
+            kwargs.setdefault("to_delete", {})
+            if self.cached_registry_proto:
+                self._registry_store.update_registry_proto(self.cached_registry_proto, **kwargs)
+        elif self.cached_registry_proto:
             self._registry_store.update_registry_proto(self.cached_registry_proto)
 
-    def refresh(self):
+    def validate_infra_update(self, update_infra):
+        if "dkuberegistrystore" == self._registry_store.__class__.__name__.lower():
+            self._registry_store.validate_infra_update_with_registry(update_infra)
+
+    def refresh(self, project: str=None):
         """Refreshes the state of the registry cache by fetching the registry state from the remote registry store."""
-        self._get_registry_proto(allow_cache=False)
+        self._get_registry_proto(allow_cache=False, project=project)
 
-    def teardown(self):
+    def teardown(self, **kwargs):
         """Tears down (removes) the registry."""
-        self._registry_store.teardown()
+        if "dkuberegistrystore" == self._registry_store.__class__.__name__.lower():
+            assert 'project' in kwargs
+            self._registry_store.teardown(project=kwargs['project'])
+        else:
+            self._registry_store.teardown()
 
-    def _prepare_registry_for_changes(self):
+    def _prepare_registry_for_changes(self, project: str=None):
         """Prepares the Registry for changes by refreshing the cache if necessary."""
         try:
-            self._get_registry_proto(allow_cache=True)
+            self._get_registry_proto(allow_cache=True, project=project)
         except FileNotFoundError:
             registry_proto = RegistryProto()
             registry_proto.registry_schema_version = REGISTRY_SCHEMA_VERSION
@@ -682,7 +699,7 @@ class Registry:
             self.cached_registry_proto_created = datetime.now()
         return self.cached_registry_proto
 
-    def _get_registry_proto(self, allow_cache: bool = False) -> RegistryProto:
+    def _get_registry_proto(self, allow_cache: bool = False, project: str = None) -> RegistryProto:
         """Returns the cached or remote registry state
 
         Args:
@@ -706,7 +723,10 @@ class Registry:
 
         try:
             self.cache_being_updated = True
-            registry_proto = self._registry_store.get_registry_proto()
+            if "dkuberegistrystore" == self._registry_store.__class__.__name__.lower():
+                registry_proto = self._registry_store.get_registry_proto(project=project)
+            else:
+                registry_proto = self._registry_store.get_registry_proto()
             self.cached_registry_proto = registry_proto
             self.cached_registry_proto_created = datetime.now()
         except Exception as e:
@@ -734,3 +754,57 @@ class Registry:
             fv.spec.name: fv for fv in self.cached_registry_proto.request_feature_views
         }
         return {**odfvs, **fvs, **request_fvs}
+
+    def get_existing_project_attrs(self, project):
+        registry_proto = self._registry_store.get_registry_proto(project=project)
+        existing_entities = {
+            ent.spec.name: ent
+            for ent in registry_proto.entities
+        }
+        existing_feature_svcs ={
+            fsvc.spec.name: fsvc
+            for fsvc in registry_proto.feature_services
+        }
+        existing_feature_tables = {
+            ft.spec.name: ft
+            for ft in registry_proto.feature_tables
+        }
+        existing_odfvs = {
+            fv.spec.name: fv
+            for fv in registry_proto.on_demand_feature_views
+        }
+        existing_fvs = {fv.spec.name: fv for fv in registry_proto.feature_views}
+        existing_request_fvs = {
+            fv.spec.name: fv for fv in registry_proto.request_feature_views
+        }
+
+        existing_attrs = {
+            "entities": existing_entities,
+            "feature_services": existing_feature_svcs,
+            "feature_tables": existing_feature_tables,
+            "odfvs": existing_odfvs,
+            "feature_views": existing_fvs,
+            "request_feature_views": existing_request_fvs
+
+        }
+        return existing_attrs
+
+    def update_newly_added_attrs(self, project, infra_update):
+        existing_attrs = self.get_existing_project_attrs(project=project)
+        to_add = infra_update["to_add"]
+        for k, v in to_add.items():
+            if k == "entities":
+                to_add["entities"] = list(filter(
+                    lambda entity: entity["name"] not in existing_attrs["entities"], v))
+            elif k == "feature_views":
+                to_add["feature_views"] = list(filter(
+                    lambda fv: fv["name"] not in existing_attrs["feature_views"], v))
+            elif k == "odfvs":
+                to_add["odfvs"] = list(filter(
+                    lambda odfv: odfv not in existing_attrs["odfvs"], v))
+            elif k == "feature_services":
+                to_add["feature_services"] = list(filter(
+                    lambda fsvc: fsvc["name"] not in existing_attrs["feature_services"], v))
+            elif k == "feature_tables":
+                to_add["feature_tables"] = list(filter(
+                    lambda ft: ft not in existing_attrs["feature_tables"], v))
diff --git a/sdk/python/feast/repo_operations.py b/sdk/python/feast/repo_operations.py
index a4ead6d0..b9e32b02 100644
--- a/sdk/python/feast/repo_operations.py
+++ b/sdk/python/feast/repo_operations.py
@@ -141,7 +141,10 @@ def apply_total(repo_config: RepoConfig, repo_path: Path, skip_source_validation
         )
         sys.exit(1)
     registry = store.registry
-    registry._initialize_registry()
+    if "dkuberegistrystore" == registry._registry_store.__class__.__name__.lower():
+        registry._initialize_registry(project=project)
+    else:
+        registry._initialize_registry()
     sys.dont_write_bytecode = True
     repo = parse_repo(repo_path)
 
diff --git a/sdk/python/setup.py b/sdk/python/setup.py
index a9fdfa82..4a837b51 100644
--- a/sdk/python/setup.py
+++ b/sdk/python/setup.py
@@ -44,17 +44,23 @@ REQUIRED = [
     "colorama>=0.3.9",
     "dill==0.3.*",
     "fastavro>=1.1.0",
-    "google-api-core>=1.23.0",
-    "googleapis-common-protos==1.52.*",
-    "grpcio>=1.34.0",
-    "grpcio-reflection>=1.34.0",
+    #"google-api-core>=1.23.0",
+    "google-api-core==2.8.2",
+    #"googleapis-common-protos==1.52.*",
+    "googleapis-common-protos==1.56.3",
+    #"grpcio>=1.34.0",
+    "grpcio==1.47.0",
+    #"grpcio-reflection>=1.34.0",
+    "grpcio-reflection==1.47.0",
     "Jinja2>=2.0.0",
     "jsonschema",
     "mmh3",
     "pandas>=1.0.0",
     "pandavro==1.5.*",
-    "protobuf>=3.10",
-    "proto-plus<1.19.7",
+    #"protobuf>=3.10",
+    "protobuf==3.19.4",
+    #"proto-plus<1.19.7",
+    "proto-plus==1.20.6",
     "pyarrow>=4.0.0",
     "pydantic>=1.0.0",
     "PyYAML>=5.4.*",
@@ -64,7 +70,7 @@ REQUIRED = [
     "tqdm==4.*",
     "fastapi>=0.68.0",
     "uvicorn[standard]>=0.14.0",
-    "proto-plus<1.19.7",
+    #"proto-plus<1.19.7",
     "tensorflow-metadata>=1.0.0,<2.0.0",
 ]
 
