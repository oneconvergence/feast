diff --git a/sdk/python/feast/data_source.py b/sdk/python/feast/data_source.py
index f5c40d24..4df5e899 100644
--- a/sdk/python/feast/data_source.py
+++ b/sdk/python/feast/data_source.py
@@ -303,7 +303,7 @@ class DataSource(ABC):
 
     @staticmethod
     @abstractmethod
-    def from_proto(data_source: DataSourceProto) -> Any:
+    def from_proto(data_source: DataSourceProto, **kwargs) -> Any:
         """
         Converts data source config in protobuf spec to a DataSource class object.
 
@@ -326,7 +326,7 @@ class DataSource(ABC):
 
         if data_source_type == DataSourceProto.SourceType.CUSTOM_SOURCE:
             cls = get_data_source_class_from_type(data_source.data_source_class_type)
-            return cls.from_proto(data_source)
+            return cls.from_proto(data_source, **kwargs)
 
         cls = get_data_source_class_from_type(_DATA_SOURCE_OPTIONS[data_source_type])
         return cls.from_proto(data_source)
diff --git a/sdk/python/feast/feature_store.py b/sdk/python/feast/feature_store.py
index 91215501..aeca4dd0 100644
--- a/sdk/python/feast/feature_store.py
+++ b/sdk/python/feast/feature_store.py
@@ -161,6 +161,10 @@ class FeatureStore:
         """Gets the project of this feature store."""
         return self.config.project
 
+    @project.setter
+    def project(self, project:str) -> None:
+        self.config.project = project
+
     def _get_provider(self) -> Provider:
         # TODO: Bake self.repo_path into self.config so that we dont only have one interface to paths
         return self._provider
@@ -1183,6 +1187,7 @@ class FeatureStore:
     @log_exceptions_and_usage
     def materialize_incremental(
         self, end_date: datetime, feature_views: Optional[List[str]] = None,
+        user: Optional[str] = None, offline_dataset: Optional[str] = None
     ) -> None:
         """
         Materialize incremental new data from the offline store into the online store.
@@ -1253,15 +1258,28 @@ class FeatureStore:
             start_date = utils.make_tzaware(start_date)
             end_date = utils.make_tzaware(end_date)
 
-            provider.materialize_single_feature_view(
-                config=self.config,
-                feature_view=feature_view,
-                start_date=start_date,
-                end_date=end_date,
-                registry=self._registry,
-                project=self.project,
-                tqdm_builder=tqdm_builder,
-            )
+            if "dkuberegistrystore" == self._registry._registry_store.__class__.__name__.lower():
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                    user=user,
+                    offline_dataset=offline_dataset
+                )
+            else:
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                )
 
             self._registry.apply_materialization(
                 feature_view, self.project, start_date, end_date,
@@ -1273,6 +1291,8 @@ class FeatureStore:
         start_date: datetime,
         end_date: datetime,
         feature_views: Optional[List[str]] = None,
+        user: Optional[str] = None,
+        offline_dataset: Optional[str] = None
     ) -> None:
         """
         Materialize data from the offline store into the online store.
@@ -1325,15 +1345,28 @@ class FeatureStore:
             start_date = utils.make_tzaware(start_date)
             end_date = utils.make_tzaware(end_date)
 
-            provider.materialize_single_feature_view(
-                config=self.config,
-                feature_view=feature_view,
-                start_date=start_date,
-                end_date=end_date,
-                registry=self._registry,
-                project=self.project,
-                tqdm_builder=tqdm_builder,
-            )
+            if "dkuberegistrystore" == self._registry._registry_store.__class__.__name__.lower():
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                    user=user,
+                    offline_dataset=offline_dataset
+                )
+            else:
+                provider.materialize_single_feature_view(
+                    config=self.config,
+                    feature_view=feature_view,
+                    start_date=start_date,
+                    end_date=end_date,
+                    registry=self._registry,
+                    project=self.project,
+                    tqdm_builder=tqdm_builder,
+                )
 
             self._registry.apply_materialization(
                 feature_view, self.project, start_date, end_date,
diff --git a/sdk/python/feast/infra/passthrough_provider.py b/sdk/python/feast/infra/passthrough_provider.py
index 8c6dd831..ff794070 100644
--- a/sdk/python/feast/infra/passthrough_provider.py
+++ b/sdk/python/feast/infra/passthrough_provider.py
@@ -95,10 +95,18 @@ class PassthroughProvider(Provider):
             Tuple[EntityKeyProto, Dict[str, ValueProto], datetime, Optional[datetime]]
         ],
         progress: Optional[Callable[[int], Any]],
+        user: Optional[str] = None,
     ) -> None:
         set_usage_attribute("provider", self.__class__.__name__)
         if self.online_store:
-            self.online_store.online_write_batch(config, table, data, progress)
+            # self.online_store.online_write_batch(config, table, data, progress)
+            registry_store = self.get_registry_type()
+            if registry_store and "dkuberegistrystore" in registry_store.lower():
+                self.online_store.online_write_batch(
+                    config, table, data, progress, user
+                )
+            else:
+                self.online_store.online_write_batch(config, table, data, progress)
 
     def offline_write_batch(
         self,
@@ -121,13 +129,34 @@ class PassthroughProvider(Provider):
         table: FeatureView,
         entity_keys: List[EntityKeyProto],
         requested_features: List[str] = None,
+        user: Optional[str] = None,
     ) -> List:
+        """ Read from online datastore.
+
+        Args:
+            config (RepoConfig): feature store config
+            table (FeatureView): FeatureView table
+            entity_keys (List[EntityKeyProto]): List of entities
+            requested_features (List[str], optional): List of requested features. Defaults to None.
+            user (Optional[str], optional): List of user. Defaults to None.
+
+        Returns:
+            List: List of result
+
+        Note:- As of now, this function doesn't gets used by online service.
+        """
         set_usage_attribute("provider", self.__class__.__name__)
         result = []
         if self.online_store:
-            result = self.online_store.online_read(
-                config, table, entity_keys, requested_features
-            )
+            registry_store = self.get_registry_type()
+            if registry_store and "dkuberegistrystore" in registry_store.lower():
+                result = self.online_store.online_read(
+                    config, table, entity_keys, requested_features, user
+                )
+            else:
+                result = self.online_store.online_read(
+                    config, table, entity_keys, requested_features
+                )
         return result
 
     def ingest_df(
@@ -163,6 +192,8 @@ class PassthroughProvider(Provider):
         registry: BaseRegistry,
         project: str,
         tqdm_builder: Callable[[int], tqdm],
+        user: Optional[str] = None,
+        offline_dataset: Optional[str] = None
     ) -> None:
         set_usage_attribute("provider", self.__class__.__name__)
 
@@ -177,16 +208,44 @@ class PassthroughProvider(Provider):
             created_timestamp_column,
         ) = _get_column_names(feature_view, entities)
 
-        offline_job = self.offline_store.pull_latest_from_table_or_query(
-            config=config,
-            data_source=feature_view.batch_source,
-            join_key_columns=join_key_columns,
-            feature_name_columns=feature_name_columns,
-            timestamp_field=timestamp_field,
-            created_timestamp_column=created_timestamp_column,
-            start_date=start_date,
-            end_date=end_date,
-        )
+        # offline_job = self.offline_store.pull_latest_from_table_or_query(
+        #     config=config,
+        #     data_source=feature_view.batch_source,
+        #     join_key_columns=join_key_columns,
+        #     feature_name_columns=feature_name_columns,
+        #     timestamp_field=timestamp_field,
+        #     created_timestamp_column=created_timestamp_column,
+        #     start_date=start_date,
+        #     end_date=end_date,
+        # )
+
+        registry_store = self.get_registry_type()
+        if registry_store and "dkuberegistrystore" in registry_store.lower():
+            offline_job = self.offline_store.pull_latest_from_table_or_query(
+                config=config,
+                data_source=feature_view.batch_source,
+                join_key_columns=join_key_columns,
+                feature_name_columns=feature_name_columns,
+                # event_timestamp_column=event_timestamp_column,
+                timestamp_field=timestamp_field,
+                created_timestamp_column=created_timestamp_column,
+                start_date=start_date,
+                end_date=end_date,
+                user=user,
+                offline_dataset=offline_dataset
+            )
+        else:
+            offline_job = self.offline_store.pull_latest_from_table_or_query(
+                config=config,
+                data_source=feature_view.batch_source,
+                join_key_columns=join_key_columns,
+                feature_name_columns=feature_name_columns,
+                # event_timestamp_column=event_timestamp_column,
+                timestamp_field=timestamp_field,
+                created_timestamp_column=created_timestamp_column,
+                start_date=start_date,
+                end_date=end_date,
+            )
 
         table = offline_job.to_arrow()
 
@@ -198,17 +257,40 @@ class PassthroughProvider(Provider):
             for entity in feature_view.entity_columns
         }
 
-        with tqdm_builder(table.num_rows) as pbar:
-            for batch in table.to_batches(DEFAULT_BATCH_SIZE):
-                rows_to_write = _convert_arrow_to_proto(
-                    batch, feature_view, join_key_to_value_type
-                )
-                self.online_write_batch(
-                    self.repo_config,
-                    feature_view,
-                    rows_to_write,
-                    lambda x: pbar.update(x),
-                )
+        # with tqdm_builder(table.num_rows) as pbar:
+        #     for batch in table.to_batches(DEFAULT_BATCH_SIZE):
+        #         rows_to_write = _convert_arrow_to_proto(
+        #             batch, feature_view, join_key_to_value_type
+        #         )
+        #         self.online_write_batch(
+        #             self.repo_config,
+        #             feature_view,
+        #             rows_to_write,
+        #             lambda x: pbar.update(x),
+        #         )
+
+        if registry_store and "dkuberegistrystore" in registry_store.lower():
+            with tqdm_builder(table.num_rows) as pbar:
+                for batch in table.to_batches(DEFAULT_BATCH_SIZE):
+                    # rows_to_write = _convert_arrow_to_proto(batch, feature_view, join_keys)
+                    rows_to_write = _convert_arrow_to_proto(batch, feature_view, join_key_to_value_type)
+                    self.online_write_batch(
+                        self.repo_config,
+                        feature_view,
+                        rows_to_write,
+                        lambda x: pbar.update(x),
+                        user
+                    )
+        else:
+            with tqdm_builder(table.num_rows) as pbar:
+                for batch in table.to_batches(DEFAULT_BATCH_SIZE):
+                    rows_to_write = _convert_arrow_to_proto(batch, feature_view, join_key_to_value_type)
+                    self.online_write_batch(
+                        self.repo_config,
+                        feature_view,
+                        rows_to_write,
+                        lambda x: pbar.update(x),
+                    )
 
     def get_historical_features(
         self,
@@ -303,3 +385,8 @@ class PassthroughProvider(Provider):
             start_date=make_tzaware(start_date),
             end_date=make_tzaware(end_date),
         )
+
+    def get_registry_type(self):
+        registry_cfg = self.repo_config.get_registry_config()
+        registry_type = registry_cfg.registry_store_type.lower()
+        return registry_type
